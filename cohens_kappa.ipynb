{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c835e69-54c3-4919-9831-8ef19f1ae148",
   "metadata": {},
   "source": [
    "# Evaluating agreement using Cohen's $\\kappa$\n",
    "\n",
    "## Calculating Cohen's $\\kappa$\n",
    "\n",
    "In this exercise, we calculate Cohen's $\\kappa$ by hand, in order to understand how the measure works.\n",
    "\n",
    "To do so, first you need to classify each of the sentences above into three categories: **positive** (`POS`), **neutral** (`NEU`) or **negative** (`NEG`).\n",
    "\n",
    "```\n",
    "1. Congratulations on your promotion! You've worked hard and truly deserve it.\n",
    "2. The test results will be available by the end of the week. Great.\n",
    "3. The report provides a detailed analysis of the market trends over the past quarter.\n",
    "4. The traffic was terrible this morning.\n",
    "5. The cat is sleeping peacefully on the windowsill.\n",
    "6. We have to cancel the event due to unforeseen circumstances.\n",
    "7. Your kindness and generosity make the world a better place.\n",
    "8. The meeting is scheduled for 2:00 PM in the conference room.\n",
    "9. I didn't hear the news about your new job opportunity.\n",
    "10. I can't believe I forgot my keys again; this is so frustrating.\n",
    "11. I'm so grateful for your help with the project; we couldn't have done it without you.\n",
    "12. The weather today is absolutely beautiful, perfect for a picnic in the park.\n",
    "13. I'm disappointed that the project didn't meet the client's expectations.\n",
    "14. The train is scheduled to arrive at the station on time.\n",
    "15. The customer service I received was extremely poor, and I'm not satisfied with the product.\n",
    "```\n",
    "\n",
    "Write your answers into the dictionary below. Write the labels (`POS`, `NEU`, `NEG`) within the empty strings (e.g. `'NEU'`).\n",
    "\n",
    "Do not discuss your decisions with your neighbour!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef9145-a738-4abe-908b-35d3b1de6b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = {\n",
    "    1: '',\n",
    "    2: '',\n",
    "    3: '',\n",
    "    4: '',\n",
    "    5: '',\n",
    "    6: '',\n",
    "    7: '',\n",
    "    8: '',\n",
    "    9: '',\n",
    "    10: '',\n",
    "    11: '',\n",
    "    12: '',\n",
    "    13: '',\n",
    "    14: '',\n",
    "    15: ''\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3561d7bb-13e5-4294-8055-b37ef81d933b",
   "metadata": {},
   "source": [
    "Next, we will start by calculating **observed agreement**, which corresponds to the number of times you chose to place the sentence in the same category as the person next to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83493e24-ea7a-4f00-92ec-8a482d48cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the number 0 with the number of items you agreed on\n",
    "agreed = 0\n",
    "\n",
    "# Divide the count with the number of items in the dictionary 'classifications'. The len() function counts the number of items.\n",
    "observed_agreement = agreed / len(classifications)\n",
    "\n",
    "# Print out the value for 'observed_agreement'\n",
    "print(observed_agreement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da352c-80cd-46fe-a311-129895638ac3",
   "metadata": {},
   "source": [
    "The problem with observed agreement is that it does not account for the possibility that you agreed by chance!\n",
    "\n",
    "In other words, the observed agreement may have been pure luck!\n",
    "\n",
    "This is why we need to estimate the possibility of agreement by chance.\n",
    "\n",
    "To do so, count how many times you used each of the three categories (`POS`, `NEU`, `NEG`).\n",
    "\n",
    "We can do this easily using the `Counter` class in Python's `collections` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e178bbfd-ab82-4b6d-889f-96f30757c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Counter class from the collections module\n",
    "from collections import Counter\n",
    "\n",
    "# Count the number of unique values in the dictionary 'classifications'\n",
    "categories = Counter(classifications.values())\n",
    "\n",
    "# Print out the result\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda7a641-b554-4746-b03d-ea29caf2faca",
   "metadata": {},
   "source": [
    "We can convert these counts into probabilities by dividing them with the total number of items in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfe8872-cbe0-46e0-80c9-fb739c8e989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the count for each category from the Counter object and divide by the total number of items\n",
    "pos = categories['POS'] / len(classifications)\n",
    "neu = categories['NEU'] / len(classifications)\n",
    "neg = categories['NEG'] / len(classifications)\n",
    "\n",
    "# Print out the probabilities for each category\n",
    "print(\"Probability for POS:\", pos)\n",
    "print(\"Probability for NEU:\", neu)\n",
    "print(\"Probability for NEG:\", neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f9ad28-c952-45fa-a439-852dc9db213d",
   "metadata": {},
   "source": [
    "These probabilities represent the chance of you assigning a sentence to this particular category.\n",
    "\n",
    "Now ask the person next to you for their probabilities for each category.\n",
    "\n",
    "Store the values into the variables below by replacing the value 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb33342-e0a1-44a5-9d61-1ac2bf8dd6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store your neighbour's probabilities for choosing each category here\n",
    "neighbour_pos = 0.33\n",
    "neighbour_neu = 0.2\n",
    "neighbour_neg = 0.47"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044f3336-ebdc-4afc-8778-d9c629b7f631",
   "metadata": {},
   "source": [
    "Now that we know the probabilities for each category for both annotators, we can calculate the probability that both annotators chose the same category by chance.\n",
    "\n",
    "This is easy: for each category, simply multiply your probability with the corresponding probability from the person next to you.\n",
    "\n",
    "If either annotator did not assign a single tweet into a category, e.g. negative, and the other annotator did, then this effectively rules out the possibility of agreeing by chance (multiplication by zero results in zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27265201-eeee-4aad-925a-dd8b49495fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probabilities for choosing the same category\n",
    "both_pos = pos * neighbour_pos\n",
    "both_neu = neu * neighbour_neu\n",
    "both_neg = neg * neighbour_neg\n",
    "\n",
    "# Print out the probabilities for chance agreement for each category\n",
    "print(\"Probability for chance agreement for POS:\", both_pos)\n",
    "print(\"Probability for chance agreement for NEU:\", both_neu)\n",
    "print(\"Probability for chance agreement for NEG:\", both_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0793e77-4f02-438c-bd63-e1f8f11a8e91",
   "metadata": {},
   "source": [
    "Next, we can calculate how likely you are to agree by chance.\n",
    "\n",
    "This is known as **expected agreement**, which is calculated by summing up the probabilities for chance agreement for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de416fc-33b7-49e8-992d-01f15f6e72b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate expected agreement\n",
    "expected_agreement = both_pos + both_neu + both_neg\n",
    "\n",
    "# Print out expected agreement\n",
    "print(expected_agreement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cee7de-6c5b-4918-99b1-7901b13f2f2d",
   "metadata": {},
   "source": [
    "Now that we know both observed agreement (stored under the variable `observed_agreement`) and the agreement expected by chance (`expected_agreement`), we can use this information to calculate Cohen's $\\kappa$.\n",
    "\n",
    "The formula for Cohen's $\\kappa$ is as follows:\n",
    "\n",
    "$\\kappa = \\frac{P_{observed} - P_{expected}}{1 - P_{expected}}$\n",
    "\n",
    "As all of the information needed is stored into the variables `observed_agreement` and `expected_agreement`, we can easily calculate the value for $\\kappa$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3243867-bfab-41e3-a59b-b4e42b111cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Cohen's kappa\n",
    "kappa = (observed_agreement - expected_agreement) / (1 - expected_agreement)\n",
    "\n",
    "# Print out the value for Cohen's kappa\n",
    "print(kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30f832e-2ec0-4350-af2e-aaad9ab4ada4",
   "metadata": {},
   "source": [
    "Which value did you get?\n",
    "\n",
    "Remember that the values for Cohen's $\\kappa$ range from $-1$ to $+1$, where $-1$ stands for perfect disagreement, while $+1$ indicates perfect agreement. A value of $0$ indicates completely random agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c1e58e-a57a-4989-ac1d-8d7b1144e905",
   "metadata": {},
   "source": [
    "## Calculating weighted Cohen's $\\kappa$\n",
    "\n",
    "It should be noted that the original $\\kappa$ score does not account for how many times each category appears in the data.\n",
    "\n",
    "Think, for example, of a situation where most items would fall within a single category – this would radically increase the possibility of chance agreement. Both annotators could simply choose to categorise each item into the dominant category, and this would result in a very high level of agreement!\n",
    "\n",
    "This issue can be mitigated by weighting observed and expected agreement by how many times each category is used by the annotators.\n",
    "\n",
    "To get started, ask your neighbour for their classifications and enter them into the dictionary below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cd2e34-9741-4241-93c8-30d01c82648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbour_classifications = {\n",
    "    1: '',\n",
    "    2: '',\n",
    "    3: '',\n",
    "    4: '',\n",
    "    5: '',\n",
    "    6: '',\n",
    "    7: '',\n",
    "    8: '',\n",
    "    9: '',\n",
    "    10: '',\n",
    "    11: '',\n",
    "    12: '',\n",
    "    13: '',\n",
    "    14: '',\n",
    "    15: ''\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfe97e1-5ebd-4048-8bfc-df19da2bfdfe",
   "metadata": {},
   "source": [
    "One rarely has to calculate agreement measures such as Cohen's $\\kappa$ by hand, as they have been implemented in numerous Python libraries.\n",
    "\n",
    "Let's import the `cohen_kappa_score` function from the `metrics` module of the *scikit-learn* library (`sklearn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae4221-007f-4cec-b74e-60982b09fa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the cohen_kappa_score function from scikit-learn's metrics module\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f7bc6a-5d59-49e9-96cc-8d0c7ea9e31d",
   "metadata": {},
   "source": [
    "Next, let's calculate Cohen's $\\kappa$ without weights – just as we did by hand above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3fa9b6-f411-4011-9197-a285915f5ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve lists of categories from both dictionaries\n",
    "cats_you = list(classifications.values())\n",
    "cats_nb = list(neighbour_classifications.values())\n",
    "\n",
    "# Input the two lists to the cohen_kappa_score function\n",
    "cohen_kappa_score(cats_you, cats_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda1ff34-4a19-464b-a80d-33d231506a3f",
   "metadata": {},
   "source": [
    "This should give you the same result that you calculated manually.\n",
    "\n",
    "If we want to take into account the distribution of categories, we can call the function with the argument `weights`.\n",
    "\n",
    "In this case, we use [quadratic weighting](https://datatab.net/tutorial/weighted-cohens-kappa) to account for the distribution of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8316e7-00a3-4ad6-bfe6-76d5fb2d72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Cohen's kappa with quadratic weights\n",
    "cohen_kappa_score(cats_you, cats_nb, weights='quadratic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b658e7-ed0d-4260-b2a9-65f370d1ed8e",
   "metadata": {},
   "source": [
    "This brief tutorial should have given you an idea of how Cohen's $\\kappa$ and other measures of agreement work.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
